{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScanBot\n",
    "\n",
    "The AI-driven bot that will read all your scanned documents and extract information into a database automatically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 1)) (1.30.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from -r requirements.txt (line 6)) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (2.7.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from openpyxl->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\d92343\\appdata\\local\\mambaforge\\envs\\azure\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import base64\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert your API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"sk-proj-iHrdMRQrydnSDtQUIzU6T3BlbkFJCoAngxToaT2u????????\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load prompts from files\n",
    "def load_prompt(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "# Function to analyze the document and extract meta data\n",
    "def analyze_document(file_path, prompt):\n",
    "    # create image data url\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        image_url = f\"data:image/jpeg;base64,{base64.b64encode(file.read()).decode()}\" # TODO! Hint: How can you send an image via an API?\n",
    "\n",
    "    # TODO! Hint: Use ChatGPT playground or Docs\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": image_url\n",
    "                            },\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=750,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        # hard coded sleep time to avoid rate limit\n",
    "        time.sleep(15)\n",
    "        return analyze_document(file_path, prompt)\n",
    "\n",
    "\n",
    "# Function to generate a filename based on meta data\n",
    "def generate_filename(meta_data):\n",
    "    # <doc type>_<date>_<title>.jpg\n",
    "    # if any of the fields are missing, use \"unknown\"\n",
    "    string = \"\"\n",
    "    string += str(meta_data.get(\"document_type\", \"unknown\")) + \"_\"\n",
    "    string += str(meta_data.get(\"author\", \"unknown\")) + \"_\"\n",
    "    string += str(meta_data.get(\"date\", \"unknown\")) + \"_\"\n",
    "    string += str(meta_data.get(\"title\", \"unknown\"))\n",
    "    # Make sure that the filename is a valid filename\n",
    "    string = re.sub(r\"[^\\w\\s-]\", \"\", string)\n",
    "    return string + \".jpg\"\n",
    "\n",
    "\n",
    "# Function to save meta data to a YAML file\n",
    "def save_meta_file(meta_data, meta_file_path):\n",
    "    # Save json file as yaml\n",
    "    with open(meta_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        yaml.dump(meta_data, file, default_flow_style=False,\n",
    "                  allow_unicode=True)\n",
    "\n",
    "\n",
    "# Function to save meta data to CSV and Excel files\n",
    "def save_meta_data_to_csv_excel(meta_data_list, csv_path, excel_path):\n",
    "    # check if the csv file exists\n",
    "    if not os.path.exists(csv_path):\n",
    "        existing_df = pd.DataFrame()\n",
    "    else:\n",
    "        existing_df = pd.read_csv(csv_path)\n",
    "\n",
    "    new_df = pd.DataFrame(meta_data_list)\n",
    "    merged_df = pd.concat([existing_df, new_df]).drop_duplicates(subset='original_filepath')\n",
    "    merged_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "    merged_df.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "def parse_meta_data(response):\n",
    "    # Get content between \"```yaml\" and \"```\" to extract meta data\n",
    "    yaml_string = response.split(\"```yaml\")[1].split(\"```\")[0]\n",
    "    meta_info = re.sub(r'(?<=: )([^\"\\n]*: [^\"\\n]*)', r'\"\\1\"', yaml_string)\n",
    "    meta_json = yaml.safe_load(meta_info)\n",
    "    return meta_json\n",
    "\n",
    "\n",
    "def save_meta_data(meta_json, file_path):\n",
    "    # Generate new file name\n",
    "    new_filename = generate_filename(meta_json)\n",
    "    # Rename the document file\n",
    "    renamed_file_location = os.path.join('database', 'renamed files',\n",
    "                                         new_filename)\n",
    "    shutil.copy2(file_path, renamed_file_location)\n",
    "    # Create meta data file\n",
    "    meta_file_path = os.path.join('database', 'meta files',\n",
    "                                  new_filename.split('.')[0] + \".yaml\")\n",
    "    save_meta_file(meta_json, meta_file_path)\n",
    "    # Add new file name to meta data\n",
    "    meta_json[\"original_filepath\"] = file_path\n",
    "    meta_json[\"renamed_filename\"] = new_filename\n",
    "    return new_filename\n",
    "\n",
    "def get_original_filenames(csv_path):\n",
    "    # Extract all \"original_filepath\" from the meta_data csv file\n",
    "    original_filepaths = []\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        original_filepaths = df[\"original_filepath\"].tolist()\n",
    "    return original_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the next cell will delete previous extractions from the `database` directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete everything inside the database folder in one line\n",
    "shutil.rmtree('database', ignore_errors=True)\n",
    "\n",
    "# First, make sure that database/meta files and database/renamed_files exist\n",
    "os.makedirs('database/meta files')\n",
    "os.makedirs('database/renamed files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the prompt first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please analyze the attached scan of a document and extract the relevant information. Create a metadata file in YAML format that includes only the following fields and nothing else:\n",
      "\n",
      "- document_type: The type or category of the document (e.g., invoice, receipt, contract, letter).\n",
      "- date: The date of the document, if available (e.g., invoice date, letter date, birthday).\n",
      "- author: The person or organization that created or sent the document.\n",
      "- recipient: The person or organization to whom the document is addressed.\n",
      "- title: The main title or subject of the document.\n",
      "- content: Extract the main content from the document as full text.\n",
      "- names: All names of persons mentioned in the document.\n",
      "- places: All locations or addresses mentioned in the document.\n",
      "- organizations: All organizations or companies mentioned in the document.\n",
      "- goods: All goods or products mentioned in the document.\n",
      "\n",
      "The response must be strictly in YAML format and contain only the metadata fields specified above, without any additional text or explanations in your response. Here is an example of the expected output in YAML format:\n",
      "\n",
      "```yaml\n",
      "document_type: Invoice\n",
      "date: 2020-12-01\n",
      "author: John Doe\n",
      "recipient: Jane Smith\n",
      "title: December Invoice for Services\n",
      "keywords: [invoice, December, payment]\n",
      "content: He worked on repairing the bike parts and provided repair services as per the agreement. The invoice is due by the end of the month...\n",
      "names: [John Doe, Jane Smith]\n",
      "places: [New York, Brooklyn]\n",
      "organizations: [ABC Repair Services, XYZ Bikes]\n",
      "goods: [bike parts, repair services]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_path = \"prompts/analyze_document.txt\"\n",
    "prompt = load_prompt(prompt_path)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ChatGPT-4o to collect information about all scanned documents; subsequently collect all data in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CV_1.jpg...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CV_1.jpg, renamed it to Curriculum Vitae_Dmitriy Yurevich Khoroshev_None_Curriculum Vitae.jpg\n",
      "Processing CV_2.jpg...\n",
      "Processed CV_2.jpg, renamed it to Curriculum Vitae_Alexei Ivanovich Petrov_None_Curriculum Vitae.jpg\n",
      "Meta data saved to database/meta_data.csv and database/meta_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "meta_data_list = []\n",
    "document_dir = \"documents\"\n",
    "csv_path = \"database/meta_data.csv\"\n",
    "excel_path = \"database/meta_data.xlsx\"\n",
    "# Extract all \"original_filepath\" from the meta_data csv file\n",
    "original_filepaths = get_original_filenames(csv_path)\n",
    "\n",
    "for filename in os.listdir(document_dir):\n",
    "    extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "    if (filename.endswith(extensions) and\n",
    "        (os.path.join(document_dir, filename) not in original_filepaths)):\n",
    "        file_path = os.path.join(document_dir, filename)\n",
    "        print(f\"Processing {filename}...\")\n",
    "        # Analyze the document to get meta data\n",
    "        llm_response = analyze_document(file_path, prompt)\n",
    "        # Parse the meta data from the response\n",
    "        meta_json = parse_meta_data(llm_response)\n",
    "        # Save the meta data and rename the document file\n",
    "        new_file_name = save_meta_data(meta_json, file_path)\n",
    "        meta_data_list.append(meta_json)\n",
    "        print(f\"Processed {filename}, renamed it to {new_file_name}\")\n",
    "\n",
    "# Save all meta data to CSV and Excel files\n",
    "save_meta_data_to_csv_excel(meta_data_list, csv_path, excel_path)\n",
    "print(f\"Meta data saved to {csv_path} and {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Now that we extracted relevant information from the documents, we want to cross check that this person is not an sanctions list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document_type': 'Curriculum Vitae',\n",
       "  'date': None,\n",
       "  'author': 'Dmitriy Yurevich Khoroshev',\n",
       "  'recipient': None,\n",
       "  'title': 'Curriculum Vitae',\n",
       "  'content': 'Name: Dmitriy Yurevich Khoroshev Date of Birth: April 17, 1993 Place of Birth: Russian Federation Nationality: Russian  Email: khoroshev1@icloud.com, sitedev5@yandex.ru Passport: 2018278055 (Russia), 2006801524 (Russia) Tax ID No: 366110340670 (Russia)\\nProfessional Experience\\nSenior Software Engineer, TechSolutions Ltd. September 2019 - May 2024\\n- Led a team of developers to design and implement software solutions. - Developed and maintained high-performance web applications. - Collaborated with cross-functional teams to define project requirements. - Ensured software quality through rigorous testing and code reviews.\\nCybersecurity Consultant June 2015 - August 2019\\n- Provided cybersecurity services to various clients. - Specialized in penetration testing and vulnerability assessment. - Developed security protocols and measures for organizations. - Trained staff on cybersecurity best practices.\\n',\n",
       "  'names': ['Dmitriy Yurevich Khoroshev'],\n",
       "  'places': ['Russian Federation'],\n",
       "  'organizations': ['TechSolutions Ltd.'],\n",
       "  'goods': None,\n",
       "  'original_filepath': 'documents\\\\CV_1.jpg',\n",
       "  'renamed_filename': 'Curriculum Vitae_Dmitriy Yurevich Khoroshev_None_Curriculum Vitae.jpg'},\n",
       " {'document_type': 'Curriculum Vitae',\n",
       "  'date': None,\n",
       "  'author': 'Alexei Ivanovich Petrov',\n",
       "  'recipient': None,\n",
       "  'title': 'Curriculum Vitae',\n",
       "  'content': 'Personal Information\\n\\nName: Alexei Ivanovich Petrov\\nDate of Birth: April 17, 1993\\nPlace of Birth: Russian Federation\\nNationality: Russian\\nEmail: alexei.petrov@protonmail.com\\nPassport: 3018278055 (Russia), 3006801524 (Russia)\\nTax ID No: 366110340670 (Russia)\\n\\nProfessional Experience\\n\\nSenior Software Engineer, TechSolutions Ltd.\\n\\nSeptember 2019 - May 2024\\n\\n- Led a team of developers to design and implement software solutions.\\n- Developed and maintained high-performance web applications.\\n- Collaborated with cross-functional teams to define project requirements.\\n- Ensured software quality through rigorous testing and code reviews.\\n- Specialized in digital currencies and blockchain technology.\\n\\nCybersecurity Consultant\\n\\nJune 2015 - August 2019\\n\\n- Provided cybersecurity services to various clients.\\n- Specialized in penetration testing and vulnerability assessment.\\n- Developed security protocols and measures for organizations.\\n- Trained staff on cybersecurity best practices.\\n',\n",
       "  'names': ['Alexei Ivanovich Petrov'],\n",
       "  'places': ['Russian Federation'],\n",
       "  'organizations': ['TechSolutions Ltd.'],\n",
       "  'goods': [],\n",
       "  'original_filepath': 'documents\\\\CV_2.jpg',\n",
       "  'renamed_filename': 'Curriculum Vitae_Alexei Ivanovich Petrov_None_Curriculum Vitae.jpg'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Dmitriy Yurevich Khoroshev', 'Alexei Ivanovich Petrov')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_cv_1 = meta_data_list[0]['names'][0]\n",
    "name_cv_2 = meta_data_list[1]['names'][0]\n",
    "content_cv_1 = meta_data_list[0]['content']\n",
    "content_cv_2 = meta_data_list[1]['content']\n",
    "name_cv_1, name_cv_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the sanctions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48603,\"khoroshev, dmitry yuryevich\",\"individua...</td>\n",
       "      <td>pob russian federation</td>\n",
       "      <td>nationality russia</td>\n",
       "      <td>citizen russia</td>\n",
       "      <td>email address khoroshev1@icloud.com</td>\n",
       "      <td>alt. email address sitedev5@yandex.ru</td>\n",
       "      <td>gender male</td>\n",
       "      <td>digital currency address - xbt bc1qvhnfknw852...</td>\n",
       "      <td>secondary sanctions risk: ukraine-/russia-rel...</td>\n",
       "      <td>passport 2018278055 (russia)</td>\n",
       "      <td>alt. passport 2006801524 (russia)</td>\n",
       "      <td>tax id no. 366110340670 (russia)</td>\n",
       "      <td>a.k.a. 'lockbitsupp'.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48604,\"seliverstov, ivan vladimirovich\",\"indiv...</td>\n",
       "      <td>pob magdeburg, germany</td>\n",
       "      <td>nationality russia</td>\n",
       "      <td>gender male.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48605,\"gopstein, ben-zion\",\"individual\",\"west-...</td>\n",
       "      <td>nationality israel</td>\n",
       "      <td>gender male</td>\n",
       "      <td>national id no. 024526394 (israel).\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48607,\"militechtrade limited liability company...</td>\n",
       "      <td>tax id no. 9706027480 (russia)</td>\n",
       "      <td>registration number 1227700679216 (russia).\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48849,\"federal state budgetary institution 48t...</td>\n",
       "      <td>organization established date 07 apr 1928</td>\n",
       "      <td>target type government entity</td>\n",
       "      <td>tax id no. 5042129453 (russia)</td>\n",
       "      <td>registration number 1136441000706 (russia)</td>\n",
       "      <td>a.k.a. 'scientific research institute of medi...</td>\n",
       "      <td>a.k.a. 'the virology center'</td>\n",
       "      <td>a.k.a. 'scientific research institute of micr...</td>\n",
       "      <td>a.k.a. 'scientific research institute of epid...</td>\n",
       "      <td>a.k.a. 'military technical scientific researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  48603,\"khoroshev, dmitry yuryevich\",\"individua...   \n",
       "1  48604,\"seliverstov, ivan vladimirovich\",\"indiv...   \n",
       "2  48605,\"gopstein, ben-zion\",\"individual\",\"west-...   \n",
       "3  48607,\"militechtrade limited liability company...   \n",
       "4  48849,\"federal state budgetary institution 48t...   \n",
       "\n",
       "                                           1   \\\n",
       "0                      pob russian federation   \n",
       "1                      pob magdeburg, germany   \n",
       "2                          nationality israel   \n",
       "3              tax id no. 9706027480 (russia)   \n",
       "4   organization established date 07 apr 1928   \n",
       "\n",
       "                                              2   \\\n",
       "0                             nationality russia   \n",
       "1                             nationality russia   \n",
       "2                                    gender male   \n",
       "3   registration number 1227700679216 (russia).\"   \n",
       "4                  target type government entity   \n",
       "\n",
       "                                      3   \\\n",
       "0                         citizen russia   \n",
       "1                          gender male.\"   \n",
       "2   national id no. 024526394 (israel).\"   \n",
       "3                                    NaN   \n",
       "4         tax id no. 5042129453 (russia)   \n",
       "\n",
       "                                            4   \\\n",
       "0          email address khoroshev1@icloud.com   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4   registration number 1136441000706 (russia)   \n",
       "\n",
       "                                                  5   \\\n",
       "0              alt. email address sitedev5@yandex.ru   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4   a.k.a. 'scientific research institute of medi...   \n",
       "\n",
       "                              6   \\\n",
       "0                    gender male   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4   a.k.a. 'the virology center'   \n",
       "\n",
       "                                                  7   \\\n",
       "0   digital currency address - xbt bc1qvhnfknw852...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4   a.k.a. 'scientific research institute of micr...   \n",
       "\n",
       "                                                  8   \\\n",
       "0   secondary sanctions risk: ukraine-/russia-rel...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4   a.k.a. 'scientific research institute of epid...   \n",
       "\n",
       "                                                  9   \\\n",
       "0                       passport 2018278055 (russia)   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4   a.k.a. 'military technical scientific researc...   \n",
       "\n",
       "                                   10                                 11  \\\n",
       "0   alt. passport 2006801524 (russia)   tax id no. 366110340670 (russia)   \n",
       "1                                 NaN                                NaN   \n",
       "2                                 NaN                                NaN   \n",
       "3                                 NaN                                NaN   \n",
       "4                                 NaN                                NaN   \n",
       "\n",
       "                        12  \n",
       "0   a.k.a. 'lockbitsupp'.\"  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the sanctions_list.csv file\n",
    "sanctions_list = pd.read_csv(\"sanctions_list_short.csv\", sep=\";\", delimiter=None, header=None)\n",
    "# lower case entire dataframe\n",
    "sanctions_list = sanctions_list.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "sanctions_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all columns to one column\n",
    "sanctions_list[\"combined\"] = sanctions_list.apply(lambda row: \" \".join(row.dropna()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easy case: Direct matches\n",
    "\n",
    "In this case, one of the attributes of the extracted data like name, email adress, passport number, etc. matches directly with an entry in the sanctions list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find a match using the name from the first CV and the sanction list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found for Khoroshev in row 0\n",
      "0           48603,\"khoroshev, dmitry yuryevich\",\"individua...\n",
      "1                                      pob russian federation\n",
      "2                                          nationality russia\n",
      "3                                              citizen russia\n",
      "4                         email address khoroshev1@icloud.com\n",
      "5                       alt. email address sitedev5@yandex.ru\n",
      "6                                                 gender male\n",
      "7            digital currency address - xbt bc1qvhnfknw852...\n",
      "8            secondary sanctions risk: ukraine-/russia-rel...\n",
      "9                                passport 2018278055 (russia)\n",
      "10                          alt. passport 2006801524 (russia)\n",
      "11                           tax id no. 366110340670 (russia)\n",
      "12                                     a.k.a. 'lockbitsupp'.\"\n",
      "combined    48603,\"khoroshev, dmitry yuryevich\",\"individua...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for name in name_cv_1.split(' '): \n",
    "    match = sanctions_list.apply(lambda row: row.astype(str).str.contains(name.lower()).any(), axis=1)\n",
    "    if match.any():\n",
    "        print(f\"Match found for {name} in row {match[match].index[0]}\")\n",
    "        print(sanctions_list.loc[match[match].index[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second CV there's no match found in the sanctions list. Good, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_cv_2.split(' '): \n",
    "    match = sanctions_list.apply(lambda row: row.astype(str).str.contains(name.lower()).any(), axis=1)\n",
    "    if match.any():\n",
    "        print(f\"Match found for {name} in row {match[match].index[0]}\")\n",
    "        print(sanctions_list.loc[match[match].index[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hard case: A person tries to fake its identity.\n",
    "In this case full-text search is not sufficient as the hard facts about a person are alterered (Name, passport id, etc.). But we can hope that the sanctioned person or company was sloppy in covering all traces. In this case, we can try to vectorize both the collected CV data and the sanctions list and check the top matches.\n",
    "\n",
    "The top matches can be disregarded entirely, if the similarity is below some threshold. \n",
    "Above some threshold, additional checks can be triggered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/embeddings/use-cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def get_similarity(document_embedding, vector_base):\n",
    "   similarities = vector_base.map(lambda x: cosine_similarity([x], [document_embedding])[0][0])\n",
    "   return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all embeddings from both the CVs and the sanctions database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanctions_list['ada_embedding'] = sanctions_vector_base = sanctions_list.combined.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "\n",
    "cv_1_embedding = get_embedding(content_cv_1)\n",
    "cv_2_embedding = get_embedding(content_cv_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similarity between CV 1 and the sanctions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.727150\n",
       "1    0.489509\n",
       "2    0.237508\n",
       "3    0.411932\n",
       "4    0.390976\n",
       "5    0.350561\n",
       "Name: combined, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(cv_1_embedding, sanctions_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.572706\n",
       "1    0.481862\n",
       "2    0.279866\n",
       "3    0.422896\n",
       "4    0.365666\n",
       "5    0.351010\n",
       "Name: combined, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(cv_2_embedding, sanctions_vector_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found earlier that the name of the applicant in CV 1 matches directly with an entry in the sanctions list (the first entry). This is also reflected by the cosine similarity, which is largest with respect to the correct match of the sanctions list. The similarity is mainly large because of matching names, email adresses and passport numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the second CV for which no direct match was found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite no perfect matches between various attributes, there is a suspiciuously large similarity to the first entry in the sanctions list. Why could that be?\n",
    "\n",
    "In order to figure that out, we can leverage a popular **explainable AI** method: *Counterfactual what-if analysis*\n",
    "\n",
    "In such an analysis we specify some goal and try to modify the inputs such that the specified target is achieved. In this case, we want to change the CV content such that the cosine similarity isn't suspicious anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Dmitriy Yurevich Khoroshev Date of Birth: April 17, 1993 Place of Birth: Russian Federation Nationality: Russian  Email: khoroshev1@icloud.com, sitedev5@yandex.ru Passport: 2018278055 (Russia), 2006801524 (Russia) Tax ID No: 366110340670 (Russia)\\nProfessional Experience\\nSenior Software Engineer, TechSolutions Ltd. September 2019 - May 2024\\n- Led a team of developers to design and implement software solutions. - Developed and maintained high-performance web applications. - Collaborated with cross-functional teams to define project requirements. - Ensured software quality through rigorous testing and code reviews.\\nCybersecurity Consultant June 2015 - August 2019\\n- Provided cybersecurity services to various clients. - Specialized in penetration testing and vulnerability assessment. - Developed security protocols and measures for organizations. - Trained staff on cybersecurity best practices.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_list[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_cv_2 = 'Personal Information\\n\\nName: Alexei Ivanovich Petrov\\nPlace of Birth: France, Paris\\nNationality: French\\nEmail: alexei.petrov@protonmail.com\\n\\nProfessional Experience\\n\\nSenior Software Engineer, TechSolutions Ltd.\\n\\nSeptember 2019 - May 2024\\n\\n- Led a team of developers to design and implement software solutions.\\n- Developed and maintained high-performance web applications.\\n- Collaborated with cross-functional teams to define project requirements.\\n- Ensured software quality through rigorous testing and code reviews.\\n\\nCybersecurity Consultant\\n\\nJune 2015 - August 2019\\n\\n- Provided cybersecurity services to various clients.\\n- Specialized in penetration testing and vulnerability assessment.\\n- Developed security protocols and measures for organizations.\\n- Trained staff on cybersecurity best practices.\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.488156\n",
       "1    0.414368\n",
       "2    0.230206\n",
       "3    0.350396\n",
       "4    0.307408\n",
       "5    0.304089\n",
       "Name: combined, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_cv_2_embedding = get_embedding(modified_cv_2)\n",
    "get_similarity(modified_cv_2_embedding, sanctions_vector_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is actually quite hard not to get a suspicious similarity score without changing almost all details of the CV. Note however, that a high similarity score is not proof that the person of the CV is the same as the person on the sanctions list. But it can serve as an early warning system triggering a more thorough analysis, by collection more information, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
